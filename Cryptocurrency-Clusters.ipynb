{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e70c48",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45427c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "X_test= pd.read_csv('input_test.csv')\n",
    "X_train_raw = pd.read_csv('input_train.csv')\n",
    "y_random_raw = pd.read_csv('y_rand.csv')\n",
    "y_train_raw = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209957c",
   "metadata": {},
   "source": [
    "# Small preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1585bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPLACING MISSING VALUES WITH THE MEDIAN VALUE\n",
    "\n",
    "for i in X_train_raw.columns:\n",
    "    median = np.nanmedian(np.array(X_train_raw[[i]]).flatten())\n",
    "    X_train_raw[[i]] = X_train_raw[[i]].fillna(median)\n",
    "    median = np.nanmedian(np.array(X_test[[i]]).flatten())\n",
    "    X_test[[i]] = X_test[[i]].fillna(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96393228",
   "metadata": {},
   "source": [
    "# Assigning each target with its observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7ba146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>day</th>\n",
       "      <th>asset</th>\n",
       "      <th>md</th>\n",
       "      <th>bc</th>\n",
       "      <th>ret_1</th>\n",
       "      <th>ret_2</th>\n",
       "      <th>ret_3</th>\n",
       "      <th>ret_4</th>\n",
       "      <th>...</th>\n",
       "      <th>ret_15</th>\n",
       "      <th>ret_16</th>\n",
       "      <th>ret_17</th>\n",
       "      <th>ret_18</th>\n",
       "      <th>ret_19</th>\n",
       "      <th>ret_20</th>\n",
       "      <th>ret_21</th>\n",
       "      <th>ret_22</th>\n",
       "      <th>ret_23</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.734573</td>\n",
       "      <td>0.125855</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>-0.002736</td>\n",
       "      <td>-0.005487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>-0.002372</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.007140</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>0.006903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-5.813696</td>\n",
       "      <td>0.418711</td>\n",
       "      <td>-0.042280</td>\n",
       "      <td>-0.009460</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.006000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005726</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>-0.003268</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>-5.814399</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>-0.007442</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>-0.007093</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>-0.004677</td>\n",
       "      <td>-0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>-5.814399</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>-0.018364</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009794</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.002959</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>-0.005579</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>-0.010005</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>-0.004196</td>\n",
       "      <td>0.011333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>-5.814399</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>-0.010507</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018505</td>\n",
       "      <td>-0.010855</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>-0.002648</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>-0.004069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491033</th>\n",
       "      <td>491033</td>\n",
       "      <td>1463</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.219044</td>\n",
       "      <td>0.504312</td>\n",
       "      <td>-0.011203</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>-0.006468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001828</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.045506</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>-0.031109</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>-0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491034</th>\n",
       "      <td>491034</td>\n",
       "      <td>1463</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.219044</td>\n",
       "      <td>0.504312</td>\n",
       "      <td>-0.000611</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>-0.013038</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031028</td>\n",
       "      <td>-0.035453</td>\n",
       "      <td>-0.018734</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>-0.019636</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>-0.003147</td>\n",
       "      <td>0.003541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491035</th>\n",
       "      <td>491035</td>\n",
       "      <td>1463</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.219044</td>\n",
       "      <td>0.504312</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>-0.011277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>-0.005535</td>\n",
       "      <td>-0.004638</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>-0.013485</td>\n",
       "      <td>-0.009192</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491036</th>\n",
       "      <td>491036</td>\n",
       "      <td>1463</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.648535</td>\n",
       "      <td>0.622304</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-0.023664</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>-0.009081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>-0.012922</td>\n",
       "      <td>-0.008727</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491037</th>\n",
       "      <td>491037</td>\n",
       "      <td>1463</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.214598</td>\n",
       "      <td>0.219784</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>-0.000882</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007083</td>\n",
       "      <td>-0.001932</td>\n",
       "      <td>-0.012458</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>0.015325</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>-0.001651</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.006041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491038 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  cluster  day  asset        md        bc     ret_1     ret_2  \\\n",
       "0            0        0   17     10 -5.734573  0.125855 -0.002060  0.005848   \n",
       "1            1        0    0     13 -5.813696  0.418711 -0.042280 -0.009460   \n",
       "2            2        0   20     12 -5.814399  0.500111  0.003665 -0.010841   \n",
       "3            3        0   19     12 -5.814399  0.500111 -0.018364  0.003789   \n",
       "4            4        0   18     12 -5.814399  0.500111 -0.001589  0.011711   \n",
       "...        ...      ...  ...    ...       ...       ...       ...       ...   \n",
       "491033  491033     1463    7      4 -8.219044  0.504312 -0.011203  0.002543   \n",
       "491034  491034     1463    8      4 -8.219044  0.504312 -0.000611  0.013210   \n",
       "491035  491035     1463    9      4 -8.219044  0.504312 -0.002688 -0.006124   \n",
       "491036  491036     1463   17      3 -7.648535  0.622304  0.000211 -0.023664   \n",
       "491037  491037     1463    1      0 -4.214598  0.219784  0.050200  0.008255   \n",
       "\n",
       "           ret_3     ret_4  ...    ret_15    ret_16    ret_17    ret_18  \\\n",
       "0      -0.002736 -0.005487  ... -0.000339  0.001018 -0.002372 -0.000340   \n",
       "1      -0.005173 -0.006000  ... -0.005726  0.006993 -0.003268  0.015574   \n",
       "2       0.007557  0.004981  ... -0.000170 -0.002833 -0.007442 -0.001832   \n",
       "3       0.011795  0.016029  ... -0.009794 -0.001023 -0.002959  0.002568   \n",
       "4      -0.010507 -0.002555  ... -0.018505 -0.010855  0.002022  0.001211   \n",
       "...          ...       ...  ...       ...       ...       ...       ...   \n",
       "491033 -0.001614 -0.006468  ... -0.001828  0.000462  0.009613  0.003174   \n",
       "491034 -0.013038  0.006605  ... -0.031028 -0.035453 -0.018734  0.008217   \n",
       "491035  0.005423 -0.011277  ...  0.002543 -0.005535 -0.004638  0.002097   \n",
       "491036  0.000866 -0.009081  ...  0.007603  0.006057  0.002429  0.005269   \n",
       "491037 -0.000882  0.000981  ... -0.007083 -0.001932 -0.012458 -0.006282   \n",
       "\n",
       "          ret_19    ret_20    ret_21    ret_22    ret_23    target  \n",
       "0      -0.000680 -0.007140  0.006849  0.002041 -0.001697  0.006903  \n",
       "1      -0.010492  0.004486  0.011368  0.001606  0.000401  0.000301  \n",
       "2      -0.005677 -0.007093  0.001626  0.004349 -0.004677 -0.001543  \n",
       "3      -0.005579  0.001317 -0.010005  0.004677 -0.004196  0.011333  \n",
       "4      -0.002648  0.001559 -0.001153  0.000635  0.001961 -0.004069  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "491033  0.003164  0.045506  0.004309 -0.031109  0.004429 -0.000977  \n",
       "491034  0.000959 -0.019636  0.004641  0.004376 -0.003147  0.003541  \n",
       "491035 -0.013485 -0.009192  0.007136 -0.008030  0.010714  0.002779  \n",
       "491036 -0.007338 -0.000739  0.005918 -0.012922 -0.008727  0.001465  \n",
       "491037  0.015325  0.004832 -0.009270 -0.001651 -0.000050  0.006041  \n",
       "\n",
       "[491038 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.assign(target = np.nan)\n",
    "for cluster in range (0,1464):\n",
    "    for day in range (0,21):\n",
    "        i = cluster\n",
    "        j = day\n",
    "        if not y_train_raw.loc[y_train_raw['sample_id'] == cluster*21 + day,'target'].empty:\n",
    "            X_train_raw.loc[(X_train_raw['cluster']==cluster)&(X_train_raw['day'] == day), 'target'] = y_train_raw.loc[y_train_raw['sample_id'] == cluster*21 + day,'target'].values[0]\n",
    "X_train = X_train_raw.loc[X_train_raw['target'].notna()]\n",
    "X_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc66f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train.pop('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e72af",
   "metadata": {},
   "source": [
    "# Dropping useless features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab606158",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['md','id', 'asset','cluster','day'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b64744",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred = X_test.drop(['md','id', 'asset','cluster','day'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d3d66",
   "metadata": {},
   "source": [
    "# Example of randomized search with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b6bf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79075c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 192 is smaller than n_iter=200. Running 192 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 192 candidates, totalling 384 fits\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 8.3min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 7.6min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.5min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.5min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 7.0min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 6.9min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.2min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.002, test=-0.007) total time= 6.9min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.5min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.2min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 6.9min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.002, test=-0.007) total time= 6.5min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.0min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.3min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.007, test=-0.008) total time= 3.0min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.0min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 7.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 7.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 6.9min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 6.9min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.004, test=-0.007) total time= 6.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.2min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.002, test=-0.007) total time= 6.8min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.5min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.3min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 6.9min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.002, test=-0.007) total time= 6.6min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.3min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.007, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.0min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.007, test=-0.008) total time= 3.3min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.007, test=-0.008) total time= 3.0min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.007, test=-0.008) total time= 3.0min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.5min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.2min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.045, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 7.2min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 7.0min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 6.9min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 6.8min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.2min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.3min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.002, test=-0.007) total time= 6.7min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 7.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.002, test=-0.007) total time= 6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.002, test=-0.007) total time= 6.7min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=20, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 6.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.3min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.008) total time= 3.3min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.0min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.005, test=-0.007) total time= 3.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.005, test=-0.008) total time= 3.5min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.2min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.006, test=-0.007) total time= 3.4min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.005, test=-0.008) total time= 3.4min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.75, gamma=0, learning_rate=0.055, max_depth=10, min_child_weight=1, n_estimators=500, reg_lambda=0.3, subsample=0.5;, score=(train=-0.006, test=-0.008) total time= 3.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 5.2min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 5.1min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 4.6min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0, subsample=0.5;, score=(train=-0.003, test=-0.007) total time= 4.6min\n",
      "[CV 1/2] END alpha=0, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 5.0min\n",
      "[CV 2/2] END alpha=0, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=20, min_child_weight=10, n_estimators=500, reg_lambda=0.3, subsample=0.75;, score=(train=-0.003, test=-0.007) total time= 4.9min\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'max_depth': [20,10],\n",
    "    'learning_rate': [0.05,0.045,0.055],\n",
    "    'min_child_weight': [10,1],\n",
    "    'subsample':[0.75, 0.5],\n",
    "    'colsample_bytree':[0.75,0.5],\n",
    "    'gamma': [0],\n",
    "    'reg_lambda':[0,0.3],\n",
    "    'alpha':[0,0.3]\n",
    "    }\n",
    "random_cv = RandomizedSearchCV(estimator=model,\n",
    "            param_distributions=hyperparameter_grid, \n",
    "            cv=2, n_iter=200,\n",
    "            scoring = 'neg_root_mean_squared_error',n_jobs = 1,\n",
    "            return_train_score = True, verbose = 5,\n",
    "            random_state=42)\n",
    "random_cv.fit(X_train,y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed793cd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(random_cv.best_estimator_.feature_importances_, index=X_train.columns).plot.bar(figsize=(30, 8))\n",
    "#pd.DataFrame(model.feature_importances_, index=X_train.columns).plot.bar(figsize=(30, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_cv.best_params_)\n",
    "results = pd.DataFrame(random_cv.cv_results_)\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f756adbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.75,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.04, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=90, max_leaves=0, min_child_weight=20, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=4000, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.75,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.04, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=90, max_leaves=0, min_child_weight=20, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=4000, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.75,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.04, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=90, max_leaves=0, min_child_weight=20, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=4000, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27fc269",
   "metadata": {},
   "source": [
    "# Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce1a6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_data=33. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=1.0, will be overridden by sub_feature=0.8324426408004217. Current value: feature_fraction=0.8324426408004217\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_data=33. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=1.0, will be overridden by sub_feature=0.8324426408004217. Current value: feature_fraction=0.8324426408004217\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_data=33. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=1.0, will be overridden by sub_feature=0.8324426408004217. Current value: feature_fraction=0.8324426408004217\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_data=33. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=1.0, will be overridden by sub_feature=0.8324426408004217. Current value: feature_fraction=0.8324426408004217\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_data=33. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=1.0, will be overridden by sub_feature=0.8324426408004217. Current value: feature_fraction=0.8324426408004217\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;XGB&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.75,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=0,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_r...\n",
       "                               RandomForestRegressor(max_depth=84,\n",
       "                                                     max_features=&#x27;sqrt&#x27;,\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=6,\n",
       "                                                     n_estimators=200)),\n",
       "                              (&#x27;LGB&#x27;,\n",
       "                               LGBMRegressor(boosting_type=&#x27;goss&#x27;,\n",
       "                                             learning_rate=0.29154431891537524,\n",
       "                                             max_depth=104, min_data=33,\n",
       "                                             num_leaves=150,\n",
       "                                             objective=&#x27;regression&#x27;,\n",
       "                                             reg_alpha=0.10292247147901223,\n",
       "                                             reg_lambda=4.8495492608099715,\n",
       "                                             sub_feature=0.8324426408004217))],\n",
       "                  final_estimator=LinearRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;XGB&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.75,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=0,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_r...\n",
       "                               RandomForestRegressor(max_depth=84,\n",
       "                                                     max_features=&#x27;sqrt&#x27;,\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=6,\n",
       "                                                     n_estimators=200)),\n",
       "                              (&#x27;LGB&#x27;,\n",
       "                               LGBMRegressor(boosting_type=&#x27;goss&#x27;,\n",
       "                                             learning_rate=0.29154431891537524,\n",
       "                                             max_depth=104, min_data=33,\n",
       "                                             num_leaves=150,\n",
       "                                             objective=&#x27;regression&#x27;,\n",
       "                                             reg_alpha=0.10292247147901223,\n",
       "                                             reg_lambda=4.8495492608099715,\n",
       "                                             sub_feature=0.8324426408004217))],\n",
       "                  final_estimator=LinearRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XGB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.75, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=90, max_leaves=None,\n",
       "             min_child_weight=20, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=4000, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=84, max_features=&#x27;sqrt&#x27;, min_samples_leaf=9,\n",
       "                      min_samples_split=6, n_estimators=200)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LGB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(boosting_type=&#x27;goss&#x27;, learning_rate=0.29154431891537524,\n",
       "              max_depth=104, min_data=33, num_leaves=150,\n",
       "              objective=&#x27;regression&#x27;, reg_alpha=0.10292247147901223,\n",
       "              reg_lambda=4.8495492608099715, sub_feature=0.8324426408004217)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('XGB',\n",
       "                               XGBRegressor(base_score=None, booster='gbtree',\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.75,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=0,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_r...\n",
       "                               RandomForestRegressor(max_depth=84,\n",
       "                                                     max_features='sqrt',\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=6,\n",
       "                                                     n_estimators=200)),\n",
       "                              ('LGB',\n",
       "                               LGBMRegressor(boosting_type='goss',\n",
       "                                             learning_rate=0.29154431891537524,\n",
       "                                             max_depth=104, min_data=33,\n",
       "                                             num_leaves=150,\n",
       "                                             objective='regression',\n",
       "                                             reg_alpha=0.10292247147901223,\n",
       "                                             reg_lambda=4.8495492608099715,\n",
       "                                             sub_feature=0.8324426408004217))],\n",
       "                  final_estimator=LinearRegression())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressorb\n",
    "import xgboost as xb\n",
    "import lightgbm as lgb\n",
    "xgb = xb.XGBRegressor(booster = 'gbtree',colsample_bytree=0.75, gamma=0, learning_rate=0.04, max_depth=90, min_child_weight=20, n_estimators=4000, subsample=1)\n",
    "rf = RandomForestRegressor(bootstrap=True, max_depth=84, max_features='sqrt', min_samples_leaf=9, min_samples_split=6, n_estimators=200)\n",
    "LGB = lgb.LGBMRegressor(boosting_type= 'goss', learning_rate= 0.29154431891537524, max_depth= 104, min_data=33, num_leaves= 150, objective= 'regression', reg_alpha= 0.10292247147901223, reg_lambda= 4.8495492608099715, sub_feature= 0.8324426408004217)\n",
    "base_models = [\n",
    "    ('XGB', xgb),\n",
    "    ('RF', rf),\n",
    "    ('LGB', LGB)\n",
    "    ]\n",
    "stacked = StackingRegressor(\n",
    "    estimators = base_models,\n",
    "    final_estimator = LinearRegression())\n",
    "  \n",
    "stacked.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c01d64",
   "metadata": {},
   "source": [
    "# Creating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f37ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stacked.predict(X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a7be7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30744</td>\n",
       "      <td>0.004072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30745</td>\n",
       "      <td>-0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30746</td>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30747</td>\n",
       "      <td>0.025043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30748</td>\n",
       "      <td>-0.007172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13128</th>\n",
       "      <td>43906</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13129</th>\n",
       "      <td>43907</td>\n",
       "      <td>-0.020267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13130</th>\n",
       "      <td>43908</td>\n",
       "      <td>-0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13131</th>\n",
       "      <td>43909</td>\n",
       "      <td>-0.003183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13132</th>\n",
       "      <td>43910</td>\n",
       "      <td>0.002199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13133 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id    target\n",
       "0          30744  0.004072\n",
       "1          30745 -0.001882\n",
       "2          30746  0.002144\n",
       "3          30747  0.025043\n",
       "4          30748 -0.007172\n",
       "...          ...       ...\n",
       "13128      43906  0.001243\n",
       "13129      43907 -0.020267\n",
       "13130      43908 -0.001842\n",
       "13131      43909 -0.003183\n",
       "13132      43910  0.002199\n",
       "\n",
       "[13133 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[['target']] = y_pred.reshape(len(y_pred),1)\n",
    "a = {'sample_id':[]}\n",
    "a['target'] = []\n",
    "for cluster in range(1464,2091):\n",
    "    for day in range(0,21):\n",
    "        if not y_random_raw.loc[y_random_raw['sample_id']==cluster*21 +day,'target'].empty:\n",
    "            a['sample_id'].append(cluster*21+day)\n",
    "            a['target'].append(X_test.loc[(X_test['cluster'] == cluster) & (X_test['day'] == day), 'target'].values[0])\n",
    "        \n",
    "submission = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b715f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Submission.csv',header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4a649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
